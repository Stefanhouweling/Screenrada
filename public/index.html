<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Screenrada ‚Äî Scroll-Stop Camera</title>
  <style>
    body{margin:0;background:#0b0b0c;color:#fff;font-family:-apple-system,system-ui,sans-serif;display:flex;flex-direction:column;align-items:center;gap:1rem;padding:1rem}
    video{width:90vw;max-width:900px;border-radius:10px;background:#000}
    #status{font-size:14px;opacity:.9}
    #link a{color:#2c7be5;text-decoration:none;font-weight:600}
  </style>
</head>
<body>
  <h2>üì∑ Screenrada ‚Äî Scroll-Stop Camera</h2>
  <video id="cam" autoplay playsinline muted></video>
  <canvas id="frame" style="display:none"></canvas>
  <div id="status">Initializing camera‚Ä¶</div>
  <div id="link">Open console ‚Üí <a href="/console.html" target="_blank">/console.html</a></div>

  <script>
    // ----- DOM refs -----
    const v = document.getElementById('cam');
    const f = document.getElementById('frame');
    const ctx = f.getContext('2d', { willReadFrequently: true });
    const statusEl = document.getElementById('status');

    // ----- Tuning (you can tweak) -----
    const GRID = 8;                   // perceptual hash grid
    const MOTION_STOP_DELTA = 0.10;   // <= 10% change counts as "stable"
    const STABLE_FRAMES = 4;          // need 4 consecutive stable frames
    const COOL_DOWN_MS = 2000;        // minimum gap between shots
    const RETAKE_DELAY_MS = 2000;     // 2s window to consider retake
    const RETAKE_DIFF = 0.20;         // >=20% change ‚áí one retake
    const SHARP_MIN = 200;            // Laplacian variance threshold (tune per device)
    const AF_PULSE_MS = 150;          // short AF pulse duration

    // ----- State -----
    let lastHash = '';
    let stableCount = 0;
    let busy = false;
    let lastShotAt = 0;
    let hashAtShot = null;
    let retakeTimer = null;
    let stream = null;
    let track = null;
    let haveAFSupport = false;
    let focusModes = [];

    // Optional: listen to /events so the console pipeline is clearly alive
    let es;
    try{
      es = new EventSource('/events');
      es.onmessage = () => {}; // no-op; console page will handle display
      es.onerror = () => {}; // ignore errors
    }catch(e){
      console.log('SSE not available:', e);
    }

    // ----- Camera -----
    async function startCamera(){
      try{
        status('üì∑ Requesting camera access...');
        
        stream = await navigator.mediaDevices.getUserMedia({
          video: {
            facingMode: 'environment',
            width: { ideal: 1920 }, 
            height: { ideal: 1080 }
          },
          audio: false
        });
        
        status('üì∑ Camera granted. Setting up...');
        v.srcObject = stream;
        await v.play();

        track = stream.getVideoTracks()[0];
        
        // set canvas to the native camera size (full frame)
        f.width = v.videoWidth || 1280;
        f.height = v.videoHeight || 720;
        
        status('‚úÖ Camera ready. Checking autofocus...');
        await enableContinuousAFIfSupported();
        
        status('‚úÖ Camera ready. I'll snap when the page stops moving.');
        loop();
      }catch(e){
        status('‚ùå Camera error: '+e.message);
        console.error('Camera initialization failed:', e);
      }
    }

    async function enableContinuousAFIfSupported(){
      try{
        if (!track?.getCapabilities) return;
        const caps = track.getCapabilities();
        focusModes = Array.isArray(caps.focusMode) ? caps.focusMode : [];
        if (focusModes.length){
          // Prefer 'continuous', else 'auto'
          const preferred = focusModes.includes('continuous') ? 'continuous'
                          : focusModes.includes('auto') ? 'auto'
                          : null;
          if (preferred){
            await track.applyConstraints({ advanced:[{ focusMode: preferred }] });
            haveAFSupport = true;
            status('üîß Continuous AF enabled.');
          }
        }
      }catch(_){ /* ignore */ }
    }

    async function pulseAF(){
      if (!haveAFSupport) return;
      try{
        const toSingle = focusModes.includes('single-shot') ? 'single-shot'
                        : focusModes.includes('auto') ? 'auto'
                        : null;
        const backTo = focusModes.includes('continuous') ? 'continuous'
                        : focusModes.includes('auto') ? 'auto'
                        : null;
        if (!toSingle || !backTo) return;
        await track.applyConstraints({ advanced:[{ focusMode: toSingle }] });
        await waitMs(AF_PULSE_MS);
        await track.applyConstraints({ advanced:[{ focusMode: backTo }] });
      }catch(_){ /* ignore soft failures */ }
    }

    // ----- Draw & hash -----
    function drawFullFrame(){
      const vw = v.videoWidth || f.width;
      const vh = v.videoHeight || f.height;
      if (f.width !== vw || f.height !== vh) { f.width = vw; f.height = vh; }
      ctx.imageSmoothingEnabled = false;
      ctx.drawImage(v, 0, 0, vw, vh);
    }

    function getHash(){
      const w=f.width, h=f.height;
      const cw = Math.floor(w/GRID), ch = Math.floor(h/GRID);
      const img = ctx.getImageData(0,0,w,h).data;
      let out = '';
      for(let gy=0; gy<GRID; gy++){
        for(let gx=0; gx<GRID; gx++){
          let sum=0, cnt=0, sy=gy*ch, sx=gx*cw;
          for(let y=sy; y<sy+ch && y<h; y++){
            for(let x=sx; x<sx+cw && x<w; x++){
              const i=(y*w+x)*4;
              sum += (img[i]+img[i+1]+img[i+2])/3;
              cnt++;
            }
          }
          out += Math.floor((sum/cnt)/32); // 0..7
        }
      }
      return out;
    }

    function diffHash(a,b){
      if(!a || !b || a.length!==b.length) return 1;
      let d=0; for(let i=0;i<a.length;i++) if(a[i]!==b[i]) d++;
      return d/a.length;
    }

    // ----- Blur detection: variance of Laplacian -----
    function laplacianVariance(){
      const w = f.width, h = f.height;
      const { data } = ctx.getImageData(0, 0, w, h);

      // quick grayscale buffer
      const gray = new Float32Array(w*h);
      for (let y=0, i=0, j=0; y<h; y++){
        for (let x=0; x<w; x++, i+=4, j++){
          gray[j] = (data[i] + data[i+1] + data[i+2]) / 3;
        }
      }

      // 4-neighborhood Laplacian: L = -4*c + n+s+e+w
      let sum=0, sumSq=0, count=0;
      for (let y=1; y<h-1; y++){
        for (let x=1; x<w-1; x++){
          const idx = y*w + x;
          const L = -4*gray[idx] + gray[idx-1] + gray[idx+1] + gray[idx-w] + gray[idx+w];
          sum += L;
          sumSq += L*L;
          count++;
        }
      }
      const mean = sum / count;
      const varL = (sumSq / count) - (mean*mean);
      return varL;
    }

    // ----- Core loop: detect "scroll stop" from camera -----
    function loop(){
      drawFullFrame();
      const h = getHash();
      const d = diffHash(h, lastHash);

      // When motion is "low" for enough frames ‚áí consider it a scroll stop
      if (!busy && d <= MOTION_STOP_DELTA) {
        if (++stableCount >= STABLE_FRAMES) {
          maybeShoot(h);
          stableCount = 0;
        }
      } else {
        stableCount = 0;
      }

      lastHash = h;
      requestAnimationFrame(loop);
    }

    // ----- Shooting logic -----
    function cooldownOver(){ return (Date.now() - lastShotAt) >= COOL_DOWN_MS; }

    function maybeShoot(currentHash){
      if (!cooldownOver()) return;
      shoot(currentHash);
    }

    async function shoot(currentHash){
      busy = true;
      lastShotAt = Date.now();
      hashAtShot = currentHash;

      try{
        status('üì∏ Autofocus pulse‚Ä¶');
        await pulseAF();

        // Measure sharpness; if soft, try one refocus pass
        drawFullFrame();
        let sharp = laplacianVariance();
        if (sharp < SHARP_MIN){
          status(`üîé Soft image (var=${Math.round(sharp)} < ${SHARP_MIN}). Refocus once‚Ä¶`);
          await pulseAF();
          await waitMs(120);
          drawFullFrame();
          sharp = laplacianVariance();
          status(`üîç Sharpness after refocus: var=${Math.round(sharp)}`);
        }else{
          status(`üü¢ Sharp enough (var=${Math.round(sharp)}). Capturing‚Ä¶`);
        }

        // Capture and send lossless full-frame PNG
        const base64 = f.toDataURL('image/png').split(',')[1];
        await fetch('/ask', {
          method:'POST',
          headers:{'Content-Type':'application/json'},
          body: JSON.stringify({ imageBase64: base64 })
        });

        status('‚úÖ Sent. Watching for ‚â•20% change (2s)‚Ä¶');

        // schedule single retake check in 2s (20% threshold)
        if (retakeTimer) clearTimeout(retakeTimer);
        retakeTimer = setTimeout(checkForRetake, RETAKE_DELAY_MS);

      }catch(e){
        status('‚ùå Capture/Send error: '+e.message);
      }finally{
        busy = false;
      }
    }

    function checkForRetake(){
      drawFullFrame();
      const newHash = getHash();
      const change = diffHash(newHash, hashAtShot || '');
      if (change >= RETAKE_DIFF) {
        status(`üîÅ Change ${Math.round(change*100)}% ‚â• 20%. Taking one retake‚Ä¶`);
        if (cooldownOver()) shoot(newHash);
      } else {
        status(`‚èπ Change ${Math.round(change*100)}% < 20%. No retake.`);
      }
      hashAtShot = null;
      retakeTimer = null;
    }

    // ----- Helpers -----
    function status(t){ statusEl.textContent = t; }
    function waitMs(ms){ return new Promise(r=>setTimeout(r, ms)); }

    // Start
    startCamera();
  </script>
</body>
</html>
